import torch
import torch.nn as nn
from tqdm import tqdm


# Positional Encoding from https://github.com/yenchenlin/nerf-pytorch/blob/1f064835d2cca26e4df2d7d130daa39a8cee1795/run_nerf_helpers.py
class Embedder:
    def __init__(self, **kwargs):
        self.kwargs = kwargs
        self.create_embedding_fn()

    def create_embedding_fn(self):
        embed_fns = []
        d = self.kwargs['input_dims']
        out_dim = 0
        if self.kwargs['include_input']:
            embed_fns.append(lambda x: x)
            out_dim += d

        max_freq = self.kwargs['max_freq_log2']
        N_freqs = self.kwargs['num_freqs']

        if self.kwargs['log_sampling']:
            freq_bands = 2.**torch.linspace(0., max_freq, steps=N_freqs)
        else:
            freq_bands = torch.linspace(2.**0., 2.**max_freq, steps=N_freqs)

        for freq in freq_bands:
            for p_fn in self.kwargs['periodic_fns']:
                embed_fns.append(lambda x, p_fn=p_fn, freq=freq: p_fn(x * freq))
                out_dim += d

        self.embed_fns = embed_fns
        self.out_dim = out_dim

    def embed(self, inputs):
        return torch.cat([fn(inputs) for fn in self.embed_fns], -1)


def get_embedder(multires):
    embed_kwargs = {
        'include_input': True,
        'input_dims': 3,
        'max_freq_log2': multires - 1,
        'num_freqs': multires,
        'log_sampling': True,
        'periodic_fns': [torch.sin, torch.cos],
    }

    embedder_obj = Embedder(**embed_kwargs)
    embed = lambda x, eo=embedder_obj: eo.embed(x)
    return embed, embedder_obj.out_dim


class FreqEncoder_torch(nn.Module):
    def __init__(
        self,
        input_dim,
        max_freq_log2,
        N_freqs,
        log_sampling=True,
        include_input=True,
        periodic_fns=(torch.sin, torch.cos)
    ):

        super().__init__()

        self.input_dim = input_dim
        self.include_input = include_input
        self.periodic_fns = periodic_fns

        self.output_dim = 0
        if self.include_input:
            self.output_dim += self.input_dim

        self.output_dim += self.input_dim * N_freqs * len(self.periodic_fns)

        if log_sampling:
            self.freq_bands = 2**torch.linspace(0, max_freq_log2, N_freqs)
        else:
            self.freq_bands = torch.linspace(2**0, 2**max_freq_log2, N_freqs)

        self.freq_bands = self.freq_bands.numpy().tolist()

    def forward(self, input, **kwargs):

        out = []
        if self.include_input:
            out.append(input)

        for i in range(len(self.freq_bands)):
            freq = self.freq_bands[i]
            for p_fn in self.periodic_fns:
                out.append(p_fn(input * freq))

        out = torch.cat(out, dim=-1)

        return out


def get_encoder(
    encoding,
    input_dim=3,
    multires=6,
    degree=4,
    num_levels=16,
    level_dim=2,
    base_resolution=16,
    log2_hashmap_size=19,
    desired_resolution=2048,
    align_corners=False,
    interpolation='linear',
    **kwargs
):

    if encoding == 'None':
        return lambda x, **kwargs: x, input_dim

    elif encoding == 'frequency_torch':
        encoder = FreqEncoder_torch(
            input_dim=input_dim, max_freq_log2=multires - 1, N_freqs=multires, log_sampling=True
        )

    elif encoding == 'frequency':    # CUDA implementation, faster than torch.
        from .freqencoder import FreqEncoder
        encoder = FreqEncoder(input_dim=input_dim, degree=multires)

    elif encoding == 'sphere_harmonics':
        from shencoder import SHEncoder
        encoder = SHEncoder(input_dim=input_dim, degree=degree)

    elif encoding == 'hashgrid':
        from .gridencoder import GridEncoder
        encoder = GridEncoder(
            input_dim=input_dim,
            num_levels=num_levels,
            level_dim=level_dim,
            base_resolution=base_resolution,
            log2_hashmap_size=log2_hashmap_size,
            desired_resolution=desired_resolution,
            gridtype='hash',
            align_corners=align_corners,
            interpolation=interpolation
        )

    elif encoding == 'tiledgrid':
        from .gridencoder import GridEncoder
        encoder = GridEncoder(
            input_dim=input_dim,
            num_levels=num_levels,
            level_dim=level_dim,
            base_resolution=base_resolution,
            log2_hashmap_size=log2_hashmap_size,
            desired_resolution=desired_resolution,
            gridtype='tiled',
            align_corners=align_corners,
            interpolation=interpolation
        )

    else:
        raise NotImplementedError(
            'Unknown encoding mode, choose from [None, frequency, sphere_harmonics, hashgrid, tiledgrid]'
        )

    return encoder, encoder.output_dim


# MLP + Positional Encoding
class Decoder(torch.nn.Module):
    def __init__(self, input_dims=3, internal_dims=128, output_dims=4, hidden=8, multires=5):
        super().__init__()
        self.embed_fn = None
        if multires > 0:
            embed_fn, input_ch = get_embedder(multires)
            self.embed_fn = embed_fn
            input_dims = input_ch

        net = (torch.nn.Linear(input_dims, internal_dims, bias=False), torch.nn.ReLU())
        for i in range(hidden - 1):
            net = net + (torch.nn.Linear(internal_dims, internal_dims, bias=False), torch.nn.ReLU())
        net = net + (torch.nn.Linear(internal_dims, output_dims, bias=False), )
        self.net = torch.nn.Sequential(*net)

    def forward(self, p):
        if self.embed_fn is not None:
            p = self.embed_fn(p)
        out = self.net(p)
        return out

    def pre_train_sphere(self, iter, device='cuda', axis_scale=1.):
        print("Initialize SDF to sphere")
        loss_fn = torch.nn.MSELoss()
        optimizer = torch.optim.Adam(list(self.parameters()), lr=1e-4)

        for i in tqdm(range(iter)):
            p = torch.rand((1024, 3), device=device) - 0.5
            p = p / axis_scale
            ref_value = torch.sqrt((p**2).sum(-1)) - 0.3
            output = self(p)
            loss = loss_fn(output[..., 0], ref_value)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

        print("Pre-trained MLP", loss.item())


class HashDecoder(nn.Module):
    def __init__(
        self,
        input_dims=3,
        internal_dims=32,
        output_dims=4,
        hidden=2,
        input_bounds=None,
        max_res=1024,
        num_levels=16,
        interpolation='smoothstep'
    ) -> None:
        super().__init__()
        self.input_bounds = input_bounds
        self.embed_fn, input_dims = get_encoder(
            'hashgrid',
            input_dim=3,
            log2_hashmap_size=19,
            desired_resolution=max_res,
            num_levels=num_levels,
            interpolation=interpolation
        )
        net = (torch.nn.Linear(input_dims, internal_dims, bias=False), torch.nn.ReLU())
        for i in range(hidden - 1):
            net = net + (torch.nn.Linear(internal_dims, internal_dims, bias=False), torch.nn.ReLU())
        net = net + (torch.nn.Linear(internal_dims, output_dims, bias=False), )
        self.net = torch.nn.Sequential(*net)

    def gradient(self, p):
        p.requires_grad_(True)
        if self.input_bounds is not None:
            x = (p - self.input_bounds[0]) / (self.input_bounds[1] - self.input_bounds[0])
        else:
            x = p
        if self.embed_fn is not None:
            x = self.embed_fn(x)
        y = self.net(x)
        d_output = torch.ones_like(y, requires_grad=False, device=y.device)
        gradients = torch.autograd.grad(
            outputs=y,
            inputs=p,
            grad_outputs=d_output,
            create_graph=True,
            retain_graph=True,
            only_inputs=True
        )[0]
        return gradients.unsqueeze(1)

    def forward(self, p):
        if self.input_bounds is not None:
            p = (p - self.input_bounds[0]) / (self.input_bounds[1] - self.input_bounds[0]) * 2 - 1
        if self.embed_fn is not None:
            p = self.embed_fn(p)
        out = self.net(p)
        return out
